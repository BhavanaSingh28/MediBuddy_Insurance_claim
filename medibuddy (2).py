# -*- coding: utf-8 -*-
"""MediBuddy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/190nMWsQldwvbVcRU4INQFGcANgVMBEaR
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor

file1 = '/MedibuddyInsuranceDataPrice.xlsx'
file2 = '/Medibuddyinsurancedatapersonaldetails.xlsx'

# Load the datasets
df_price = pd.read_excel(file1)
df_personal = pd.read_excel(file2)

print("Insurance Price Data Info:")
df_price.info()
print("\nPersonal Details Data Info:")
df_personal.info()

print("Columns in df_price:", df_price.columns)
print("Columns in df_personal:", df_personal.columns)

# Merge datasets on common key (corrected from 'ID' to 'Policy no.')
df = pd.merge(df_price, df_personal, on='Policy no.', how='inner')

# Dislay first few rows
print("\nMerged Data Preview:")
print(df.head())

# Gender-based policy extension analysis
plt.figure(figsize=(6,4))
sns.countplot(x='sex', data=df)
plt.title('Distribution of Policies by Gender')
plt.show()

# Ensure all column names are stripped of leading/trailing whitespace
df.columns = df.columns.str.strip()

# Print column names to verify
print("Columns in df:", df.columns.tolist())

# Now, create the boxplot using the correct column names.
plt.figure(figsize=(8,5))
sns.boxplot(x='sex', y='charges in INR', data=df)
plt.title('Amount Spent on Policies by Gender')
plt.show()

# Geographic location-based policy analysis
plt.figure(figsize=(10,6))
sns.boxplot(x='region', y='charges in INR', data=df)
plt.xticks(rotation=45)
plt.title('Amount Spent on Policies by Region')
plt.show()

# Number of dependents and amount claimed
plt.figure(figsize=(8,5))
sns.boxplot(x='children', y='charges in INR', data=df)
plt.title('Amount Spent vs. Number of Dependents')
plt.show()

# BMI vs. insurance claim
plt.figure(figsize=(8,5))
sns.scatterplot(x='bmi', y='charges in INR', hue='smoker', data=df)
plt.title('BMI vs. Insurance Claim Amount')
plt.show()

# Age vs. insurance claim
plt.figure(figsize=(8,5))
sns.scatterplot(x='age', y='charges in INR', hue='smoker', data=df)
plt.title('Age vs. Insurance Claim Amount')
plt.show()

# Smoker vs. non-smoker insurance amount
plt.figure(figsize=(6,4))
sns.boxplot(x='smoker', y='charges in INR', data=df)
plt.title('Insurance Claim Amount by Smoking Status')
plt.show()

# Correlation heatmap
plt.figure(figsize=(10,6))
sns.heatmap(df.select_dtypes(include=['number']).corr(), annot=True, cmap='coolwarm')
plt.title('Feature Correlation Heatmap')
plt.show()

!pip install xgboost

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor

# 1. Data Preprocessing for Modeling
df_model = df.copy()

# Drop identifier columns that don't help prediction
df_model.drop(columns=['Policy no.'], inplace=True)

# Encode categorical features:
# Map binary features 'sex' and 'smoker'
df_model['sex'] = df_model['sex'].map({'male': 0, 'female': 1})
df_model['smoker'] = df_model['smoker'].map({'no': 0, 'yes': 1})

# One-hot encode the 'region' column
df_model = pd.get_dummies(df_model, columns=['region'], drop_first=True)

print("\nProcessed Data Columns:")
print(df_model.columns.tolist())

# Separate features and target variable
X = df_model.drop(columns=['charges in INR'])
y = df_model['charges in INR']

#Train-Test Split (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("\nShapes:")
print("X_train:", X_train.shape, "y_train:", y_train.shape)
print("X_test:", X_test.shape, "y_test:", y_test.shape)

# 3. Baseline Model: Linear Regression
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)
rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))
mae_lr = mean_absolute_error(y_test, y_pred_lr)
print("\nBaseline Linear Regression Performance:")
print("RMSE:", rmse_lr)
print("MAE:", mae_lr)

!pip install lightgbm

import lightgbm as lgb
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns



# Initialize the LightGBM regressor
lgb_model = lgb.LGBMRegressor(random_state=42)

# Define the hyperparameter grid for LightGBM
param_grid = {
    'n_estimators': [100, 200, 300],    # Number of boosting rounds
    'max_depth': [3, 5, 7],             # Maximum depth of each tree
    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate
    'subsample': [0.7, 0.8, 1.0]        # Subsampling ratio
}

# Set up GridSearchCV with 5-fold cross-validation
grid_search = GridSearchCV(
    estimator=lgb_model,
    param_grid=param_grid,
    scoring='neg_mean_squared_error',
    cv=5,
    verbose=1,
    n_jobs=-1
)

# Fit GridSearchCV on the training data (X_train, y_train from your pipeline)
grid_search.fit(X_train, y_train)

print("\nBest Parameters found:", grid_search.best_params_)

# Retrieve the best estimator from grid search and predict on the test set
best_lgb = grid_search.best_estimator_
y_pred_lgb = best_lgb.predict(X_test)
rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))
mae_lgb = mean_absolute_error(y_test, y_pred_lgb)

print("\nLightGBM Model Performance:")
print("RMSE:", rmse_lgb)
print("MAE:", mae_lgb)

# Plot feature importance from the best LightGBM model
lgb.plot_importance(best_lgb, max_num_features=10, importance_type='gain', figsize=(10,6))
plt.title("LightGBM Feature Importance")
plt.show()

# 5. Model Evaluation

from sklearn.metrics import r2_score
import shap
from sklearn.inspection import PartialDependenceDisplay

# Evaluate performance on the training set
y_train_pred = best_lgb.predict(X_train)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
train_mae = mean_absolute_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)

print("\nTraining Performance:")
print("RMSE:", train_rmse)
print("MAE:", train_mae)
print("R^2:", train_r2)

# Evaluate performance on the test set
test_r2 = r2_score(y_test, y_pred_lgb)
print("\nTest Performance:")
print("RMSE:", rmse_lgb)
print("MAE:", mae_lgb)
print("R^2:", test_r2)

# 5a. Plot Predicted vs. Actual Values
plt.figure(figsize=(8,6))
plt.scatter(y_test, y_pred_lgb, alpha=0.7, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Charges')
plt.ylabel('Predicted Charges')
plt.title('Actual vs. Predicted Charges')
plt.show()

# 5b. Residual Analysis
residuals = y_test - y_pred_lgb

plt.figure(figsize=(8,6))
sns.histplot(residuals, kde=True, color='green')
plt.title('Residual Distribution')
plt.xlabel('Residuals')
plt.show()

plt.figure(figsize=(8,6))
plt.scatter(y_pred_lgb, residuals, alpha=0.7, color='purple')
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Predicted Charges')
plt.ylabel('Residuals')
plt.title('Residuals vs. Predicted Charges')
plt.show()

# 5c. SHAP Analysis for Model Interpretability
!pip install shap --quiet

# Create an explainer and calculate SHAP values
explainer = shap.TreeExplainer(best_lgb)
shap_values = explainer.shap_values(X_test)

# Plot summary of feature importance (bar plot)
shap.summary_plot(shap_values, X_test, plot_type="bar", show=False)
plt.title("SHAP Feature Importance (Bar Plot)")
plt.show()

# Plot detailed SHAP summary plot
shap.summary_plot(shap_values, X_test, show=False)
plt.title("SHAP Summary Plot")
plt.show()

# 5d. Partial Dependence Plots for Key Features
#examine the partial dependence for 'age', 'bmi', and 'children'
features = ['age', 'bmi', 'children']
PartialDependenceDisplay.from_estimator(best_lgb, X_train, features, grid_resolution=20)
plt.suptitle("Partial Dependence Plots")
plt.show()

# 5e. Predict on a New Sample for Further Insights
# Note: Ensure that all one-hot encoded region columns exist. Here we set them to 0 (reference category).
new_sample = pd.DataFrame({
    'age': [40],
    'sex': [0],       # 0 = male, as mapped earlier
    'bmi': [25],
    'children': [1],
    'smoker': [0]
})

# Add region dummy columns (if any exist in X_train)
region_cols = [col for col in X_train.columns if col.startswith('region_')]
for col in region_cols:
    new_sample[col] = 0

predicted_charge = best_lgb.predict(new_sample)
print("\nPrediction for a new sample (40-year-old male, bmi=25, 1 child, non-smoker):")
print("Predicted Charge:", predicted_charge[0])

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import numpy as np

# Assume y_test are the true values and y_pred are predictions from your model
r2 = r2_score(y_test, y_pred_lgb)  # Replace y_pred_lgb with the predictions from your model if different
rmse = np.sqrt(mean_squared_error(y_test, y_pred_lgb))
mae = mean_absolute_error(y_test, y_pred_lgb)

print("Model Performance Metrics:")
print("R-squared (RÂ²):", r2)
print("Root Mean Squared Error (RMSE):", rmse)
print("Mean Absolute Error (MAE):", mae)

import joblib

# After training and tuning, save the best LightGBM model.
joblib.dump(best_lgb, "best_model.pkl")
print("Model saved as best_model.pkl")